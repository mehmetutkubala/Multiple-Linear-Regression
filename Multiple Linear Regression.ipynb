{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5024a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba466867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51adc377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  Radio  Newspaper  Sales\n",
       "0    230.1   37.8       69.2   22.1\n",
       "1     44.5   39.3       45.1   10.4\n",
       "2     17.2   45.9       69.3    9.3\n",
       "3    151.5   41.3       58.5   18.5\n",
       "4    180.8   10.8       58.4   12.9\n",
       "..     ...    ...        ...    ...\n",
       "195   38.2    3.7       13.8    7.6\n",
       "196   94.2    4.9        8.1    9.7\n",
       "197  177.0    9.3        6.4   12.8\n",
       "198  283.6   42.0       66.2   25.5\n",
       "199  232.1    8.6        8.7   13.4\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5406a7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TV           0\n",
       "Radio        0\n",
       "Newspaper    0\n",
       "Sales        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() #We examine the empty lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8abc7667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   TV         200 non-null    float64\n",
      " 1   Radio      200 non-null    float64\n",
      " 2   Newspaper  200 non-null    float64\n",
      " 3   Sales      200 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 6.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95f9d2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sales\"].max() #We examine the maximum value of sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76ef4f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>276.9</td>\n",
       "      <td>48.9</td>\n",
       "      <td>41.8</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  Radio  Newspaper  Sales\n",
       "175  276.9   48.9       41.8   27.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Sales\"]==27] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ae65f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[[\"TV\",\"Radio\",\"Newspaper\"]]\n",
    "y=df[[\"Sales\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ca0b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a14c40d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(50,activation=\"relu\"))\n",
    "model.add(Dense(50,activation=\"relu\"))\n",
    "model.add(Dense(50,activation=\"relu\"))\n",
    "model.add(Dense(50,activation=\"relu\"))\n",
    "model.add(Dense(50,activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\",loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "382b7fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "16/16 [==============================] - 1s 10ms/step - loss: 23.9328 - val_loss: 12.5471\n",
      "Epoch 2/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.5475 - val_loss: 6.8070\n",
      "Epoch 3/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.2972 - val_loss: 4.6094\n",
      "Epoch 4/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.7959 - val_loss: 4.1032\n",
      "Epoch 5/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.6980 - val_loss: 4.4386\n",
      "Epoch 6/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.5541 - val_loss: 4.4138\n",
      "Epoch 7/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.3471 - val_loss: 4.4503\n",
      "Epoch 8/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.2938 - val_loss: 4.3885\n",
      "Epoch 9/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.2669 - val_loss: 4.3451\n",
      "Epoch 10/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.0877 - val_loss: 4.5214\n",
      "Epoch 11/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.0234 - val_loss: 4.4481\n",
      "Epoch 12/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.0085 - val_loss: 4.2685\n",
      "Epoch 13/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.2347 - val_loss: 4.1404\n",
      "Epoch 14/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.2358 - val_loss: 4.2203\n",
      "Epoch 15/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.0551 - val_loss: 4.6017\n",
      "Epoch 16/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.8283 - val_loss: 3.9175\n",
      "Epoch 17/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.0060 - val_loss: 5.5373\n",
      "Epoch 18/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.9308 - val_loss: 3.7880\n",
      "Epoch 19/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.9334 - val_loss: 4.0328\n",
      "Epoch 20/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.7656 - val_loss: 3.8018\n",
      "Epoch 21/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.8864 - val_loss: 4.3191\n",
      "Epoch 22/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.9540 - val_loss: 3.4475\n",
      "Epoch 23/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.7072 - val_loss: 3.3503\n",
      "Epoch 24/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.5135 - val_loss: 4.0975\n",
      "Epoch 25/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.6393 - val_loss: 3.6252\n",
      "Epoch 26/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.5584 - val_loss: 3.2081\n",
      "Epoch 27/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3254 - val_loss: 3.7123\n",
      "Epoch 28/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3186 - val_loss: 3.5298\n",
      "Epoch 29/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3055 - val_loss: 3.2874\n",
      "Epoch 30/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1922 - val_loss: 3.1906\n",
      "Epoch 31/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2263 - val_loss: 4.2389\n",
      "Epoch 32/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3518 - val_loss: 3.2037\n",
      "Epoch 33/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4778 - val_loss: 3.1343\n",
      "Epoch 34/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2175 - val_loss: 2.7388\n",
      "Epoch 35/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3593 - val_loss: 2.9013\n",
      "Epoch 36/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2026 - val_loss: 3.1525\n",
      "Epoch 37/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0696 - val_loss: 2.5097\n",
      "Epoch 38/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0462 - val_loss: 2.5263\n",
      "Epoch 39/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9699 - val_loss: 2.4958\n",
      "Epoch 40/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0789 - val_loss: 2.5061\n",
      "Epoch 41/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9262 - val_loss: 2.7000\n",
      "Epoch 42/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9411 - val_loss: 2.7004\n",
      "Epoch 43/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8396 - val_loss: 2.7065\n",
      "Epoch 44/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8334 - val_loss: 2.5024\n",
      "Epoch 45/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7615 - val_loss: 2.4021\n",
      "Epoch 46/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7950 - val_loss: 2.2148\n",
      "Epoch 47/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8042 - val_loss: 2.1373\n",
      "Epoch 48/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7660 - val_loss: 2.5049\n",
      "Epoch 49/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7271 - val_loss: 2.1060\n",
      "Epoch 50/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6940 - val_loss: 2.0576\n",
      "Epoch 51/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7069 - val_loss: 2.0492\n",
      "Epoch 52/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9209 - val_loss: 1.8877\n",
      "Epoch 53/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7626 - val_loss: 1.9761\n",
      "Epoch 54/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 1.8538\n",
      "Epoch 55/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6770 - val_loss: 1.9254\n",
      "Epoch 56/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9299 - val_loss: 2.0899\n",
      "Epoch 57/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8473 - val_loss: 1.8223\n",
      "Epoch 58/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6704 - val_loss: 1.6890\n",
      "Epoch 59/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 1.6676\n",
      "Epoch 60/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6233 - val_loss: 1.6923\n",
      "Epoch 61/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6751 - val_loss: 2.1598\n",
      "Epoch 62/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8810 - val_loss: 2.6350\n",
      "Epoch 63/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7135 - val_loss: 1.8434\n",
      "Epoch 64/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6030 - val_loss: 1.4147\n",
      "Epoch 65/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 1.7095\n",
      "Epoch 66/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6942 - val_loss: 2.5314\n",
      "Epoch 67/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5208 - val_loss: 1.3608\n",
      "Epoch 68/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5149 - val_loss: 1.3872\n",
      "Epoch 69/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5952 - val_loss: 1.5233\n",
      "Epoch 70/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7355 - val_loss: 1.7633\n",
      "Epoch 71/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6030 - val_loss: 1.3271\n",
      "Epoch 72/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4993 - val_loss: 1.3964\n",
      "Epoch 73/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5109 - val_loss: 1.4546\n",
      "Epoch 74/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6923 - val_loss: 1.5706\n",
      "Epoch 75/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6772 - val_loss: 2.1727\n",
      "Epoch 76/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5190 - val_loss: 1.6233\n",
      "Epoch 77/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5545 - val_loss: 1.9003\n",
      "Epoch 78/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5411 - val_loss: 1.2757\n",
      "Epoch 79/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5818 - val_loss: 1.2236\n",
      "Epoch 80/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5447 - val_loss: 1.3081\n",
      "Epoch 81/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4121 - val_loss: 1.1947\n",
      "Epoch 82/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4062 - val_loss: 1.3159\n",
      "Epoch 83/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4887 - val_loss: 1.2063\n",
      "Epoch 84/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3805 - val_loss: 1.2700\n",
      "Epoch 85/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4450 - val_loss: 1.1383\n",
      "Epoch 86/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4681 - val_loss: 0.9772\n",
      "Epoch 87/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4382 - val_loss: 1.2420\n",
      "Epoch 88/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5837 - val_loss: 1.5934\n",
      "Epoch 89/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4872 - val_loss: 1.2023\n",
      "Epoch 90/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 1.0975\n",
      "Epoch 91/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3247 - val_loss: 1.4870\n",
      "Epoch 92/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4190 - val_loss: 1.0630\n",
      "Epoch 93/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3368 - val_loss: 1.2306\n",
      "Epoch 94/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3745 - val_loss: 1.5336\n",
      "Epoch 95/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7996 - val_loss: 2.1974\n",
      "Epoch 96/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8038 - val_loss: 2.7282\n",
      "Epoch 97/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7713 - val_loss: 1.0726\n",
      "Epoch 98/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4078 - val_loss: 1.3774\n",
      "Epoch 99/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4997 - val_loss: 1.1618\n",
      "Epoch 100/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3783 - val_loss: 1.1378\n",
      "Epoch 101/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3642 - val_loss: 1.1239\n",
      "Epoch 102/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3588 - val_loss: 1.2130\n",
      "Epoch 103/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3902 - val_loss: 1.0124\n",
      "Epoch 104/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4891 - val_loss: 1.2566\n",
      "Epoch 105/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5473 - val_loss: 1.3069\n",
      "Epoch 106/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3902 - val_loss: 1.1950\n",
      "Epoch 107/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3373 - val_loss: 1.1587\n",
      "Epoch 108/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 1.1614\n",
      "Epoch 109/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3673 - val_loss: 1.1359\n",
      "Epoch 110/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3324 - val_loss: 1.2685\n",
      "Epoch 111/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0577 - val_loss: 2.0252\n",
      "Epoch 112/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0381 - val_loss: 1.1436\n",
      "Epoch 113/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7064 - val_loss: 2.3561\n",
      "Epoch 114/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8074 - val_loss: 1.5381\n",
      "Epoch 115/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5775 - val_loss: 1.1884\n",
      "Epoch 116/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4602 - val_loss: 0.9497\n",
      "Epoch 117/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6832 - val_loss: 1.0643\n",
      "Epoch 118/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4392 - val_loss: 1.6111\n",
      "Epoch 119/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4877 - val_loss: 1.3067\n",
      "Epoch 120/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3192 - val_loss: 1.1319\n",
      "Epoch 121/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3000 - val_loss: 1.1118\n",
      "Epoch 122/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2924 - val_loss: 0.9948\n",
      "Epoch 123/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3610 - val_loss: 1.3226\n",
      "Epoch 124/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3928 - val_loss: 1.2996\n",
      "Epoch 125/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3188 - val_loss: 0.9249\n",
      "Epoch 126/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3071 - val_loss: 1.0493\n",
      "Epoch 127/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2702 - val_loss: 1.1489\n",
      "Epoch 128/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2460 - val_loss: 0.9759\n",
      "Epoch 129/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2838 - val_loss: 1.0765\n",
      "Epoch 130/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2931 - val_loss: 1.1750\n",
      "Epoch 131/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2694 - val_loss: 1.0355\n",
      "Epoch 132/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2909 - val_loss: 1.2639\n",
      "Epoch 133/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3422 - val_loss: 1.2020\n",
      "Epoch 134/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4502 - val_loss: 1.1299\n",
      "Epoch 135/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2816 - val_loss: 1.0184\n",
      "Epoch 136/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3515 - val_loss: 1.5542\n",
      "Epoch 137/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5147 - val_loss: 1.2032\n",
      "Epoch 138/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3121 - val_loss: 1.3421\n",
      "Epoch 139/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4336 - val_loss: 1.1768\n",
      "Epoch 140/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2723 - val_loss: 2.1788\n",
      "Epoch 141/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5150 - val_loss: 1.1724\n",
      "Epoch 142/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3083 - val_loss: 1.3446\n",
      "Epoch 143/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3395 - val_loss: 1.1822\n",
      "Epoch 144/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2634 - val_loss: 1.0914\n",
      "Epoch 145/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2948 - val_loss: 0.8844\n",
      "Epoch 146/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2341 - val_loss: 0.9587\n",
      "Epoch 147/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2639 - val_loss: 1.2984\n",
      "Epoch 148/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2753 - val_loss: 1.0129\n",
      "Epoch 149/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3560 - val_loss: 1.3154\n",
      "Epoch 150/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6326 - val_loss: 1.6255\n",
      "Epoch 151/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5889 - val_loss: 1.0590\n",
      "Epoch 152/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4800 - val_loss: 1.2569\n",
      "Epoch 153/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2981 - val_loss: 1.0218\n",
      "Epoch 154/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2887 - val_loss: 1.0882\n",
      "Epoch 155/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 1.1107\n",
      "Epoch 156/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2983 - val_loss: 1.0019\n",
      "Epoch 157/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2676 - val_loss: 0.9869\n",
      "Epoch 158/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3359 - val_loss: 1.2078\n",
      "Epoch 159/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2891 - val_loss: 0.8809\n",
      "Epoch 160/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2313 - val_loss: 1.0539\n",
      "Epoch 161/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1931 - val_loss: 0.9862\n",
      "Epoch 162/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2020 - val_loss: 1.0756\n",
      "Epoch 163/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2097 - val_loss: 1.0190\n",
      "Epoch 164/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1704 - val_loss: 0.9695\n",
      "Epoch 165/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2496 - val_loss: 1.2642\n",
      "Epoch 166/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3618 - val_loss: 1.5829\n",
      "Epoch 167/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4094 - val_loss: 0.9331\n",
      "Epoch 168/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2333 - val_loss: 0.8508\n",
      "Epoch 169/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2348 - val_loss: 0.8901\n",
      "Epoch 170/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1937 - val_loss: 0.7856\n",
      "Epoch 171/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1889 - val_loss: 0.8929\n",
      "Epoch 172/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2149 - val_loss: 1.0004\n",
      "Epoch 173/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2152 - val_loss: 0.9896\n",
      "Epoch 174/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2715 - val_loss: 1.0806\n",
      "Epoch 175/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2865 - val_loss: 0.9701\n",
      "Epoch 176/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2750 - val_loss: 0.9082\n",
      "Epoch 177/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2353 - val_loss: 0.9831\n",
      "Epoch 178/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2076 - val_loss: 1.0045\n",
      "Epoch 179/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2122 - val_loss: 1.2452\n",
      "Epoch 180/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.9156\n",
      "Epoch 181/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2127 - val_loss: 1.0005\n",
      "Epoch 182/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1924 - val_loss: 0.9583\n",
      "Epoch 183/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3129 - val_loss: 0.9660\n",
      "Epoch 184/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 1.1321\n",
      "Epoch 185/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.7889\n",
      "Epoch 186/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2477 - val_loss: 0.8175\n",
      "Epoch 187/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1678 - val_loss: 0.8230\n",
      "Epoch 188/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1908 - val_loss: 1.0981\n",
      "Epoch 189/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3610 - val_loss: 1.1210\n",
      "Epoch 190/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2041 - val_loss: 0.9345\n",
      "Epoch 191/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3251 - val_loss: 1.0108\n",
      "Epoch 192/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4350 - val_loss: 1.0665\n",
      "Epoch 193/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3868 - val_loss: 1.0187\n",
      "Epoch 194/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4296 - val_loss: 0.9091\n",
      "Epoch 195/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2086 - val_loss: 0.7832\n",
      "Epoch 196/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4199 - val_loss: 1.0495\n",
      "Epoch 197/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3179 - val_loss: 1.0341\n",
      "Epoch 198/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3121 - val_loss: 0.7980\n",
      "Epoch 199/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1957 - val_loss: 0.8147\n",
      "Epoch 200/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2089 - val_loss: 1.1130\n",
      "Epoch 201/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2582 - val_loss: 0.9198\n",
      "Epoch 202/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1957 - val_loss: 0.7406\n",
      "Epoch 203/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2173 - val_loss: 0.8453\n",
      "Epoch 204/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.8182\n",
      "Epoch 205/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2142 - val_loss: 0.8769\n",
      "Epoch 206/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2321 - val_loss: 0.9480\n",
      "Epoch 207/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3224 - val_loss: 0.6824\n",
      "Epoch 208/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2995 - val_loss: 0.8733\n",
      "Epoch 209/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1548 - val_loss: 0.8361\n",
      "Epoch 210/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1707 - val_loss: 0.6696\n",
      "Epoch 211/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.7564\n",
      "Epoch 212/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2239 - val_loss: 1.1048\n",
      "Epoch 213/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2762 - val_loss: 0.8467\n",
      "Epoch 214/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1979 - val_loss: 0.7083\n",
      "Epoch 215/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1487 - val_loss: 0.9752\n",
      "Epoch 216/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4032 - val_loss: 0.7007\n",
      "Epoch 217/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3645 - val_loss: 1.0160\n",
      "Epoch 218/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3007 - val_loss: 0.7316\n",
      "Epoch 219/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2801 - val_loss: 0.7055\n",
      "Epoch 220/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 1.0513\n",
      "Epoch 221/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1843 - val_loss: 0.7083\n",
      "Epoch 222/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1831 - val_loss: 0.7023\n",
      "Epoch 223/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1309 - val_loss: 0.7961\n",
      "Epoch 224/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2448 - val_loss: 0.8626\n",
      "Epoch 225/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1833 - val_loss: 0.7106\n",
      "Epoch 226/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1598 - val_loss: 0.7424\n",
      "Epoch 227/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2429 - val_loss: 0.6332\n",
      "Epoch 228/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3049 - val_loss: 0.6188\n",
      "Epoch 229/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2396 - val_loss: 0.7366\n",
      "Epoch 230/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3078 - val_loss: 0.8027\n",
      "Epoch 231/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3130 - val_loss: 0.9393\n",
      "Epoch 232/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2944 - val_loss: 1.0139\n",
      "Epoch 233/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3371 - val_loss: 0.8957\n",
      "Epoch 234/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2249 - val_loss: 0.7624\n",
      "Epoch 235/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1580 - val_loss: 0.7074\n",
      "Epoch 236/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2087 - val_loss: 0.6954\n",
      "Epoch 237/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2068 - val_loss: 0.6628\n",
      "Epoch 238/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1522 - val_loss: 0.6659\n",
      "Epoch 239/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2218 - val_loss: 0.6560\n",
      "Epoch 240/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2348 - val_loss: 0.9046\n",
      "Epoch 241/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3424 - val_loss: 0.8147\n",
      "Epoch 242/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2814 - val_loss: 0.8198\n",
      "Epoch 243/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2352 - val_loss: 0.9467\n",
      "Epoch 244/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4630 - val_loss: 0.9254\n",
      "Epoch 245/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3101 - val_loss: 0.7745\n",
      "Epoch 246/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1767 - val_loss: 0.6077\n",
      "Epoch 247/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1382 - val_loss: 0.6159\n",
      "Epoch 248/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1309 - val_loss: 0.6553\n",
      "Epoch 249/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.6386\n",
      "Epoch 250/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1763 - val_loss: 0.7045\n",
      "Epoch 251/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1645 - val_loss: 0.6616\n",
      "Epoch 252/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1287 - val_loss: 0.6433\n",
      "Epoch 253/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1504 - val_loss: 0.7329\n",
      "Epoch 254/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1382 - val_loss: 0.6302\n",
      "Epoch 255/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1476 - val_loss: 0.8464\n",
      "Epoch 256/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1633 - val_loss: 0.6435\n",
      "Epoch 257/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1216 - val_loss: 0.6748\n",
      "Epoch 258/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1314 - val_loss: 0.6312\n",
      "Epoch 259/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1314 - val_loss: 0.8160\n",
      "Epoch 260/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2189 - val_loss: 0.9919\n",
      "Epoch 261/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3335 - val_loss: 1.0854\n",
      "Epoch 262/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2947 - val_loss: 0.9261\n",
      "Epoch 263/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3037 - val_loss: 0.7078\n",
      "Epoch 264/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2646 - val_loss: 0.6983\n",
      "Epoch 265/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1585 - val_loss: 0.5852\n",
      "Epoch 266/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1283 - val_loss: 0.6551\n",
      "Epoch 267/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1814 - val_loss: 0.6492\n",
      "Epoch 268/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1683 - val_loss: 0.6547\n",
      "Epoch 269/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2403 - val_loss: 0.7210\n",
      "Epoch 270/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1426 - val_loss: 0.6672\n",
      "Epoch 271/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1822 - val_loss: 0.6742\n",
      "Epoch 272/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1753 - val_loss: 0.7805\n",
      "Epoch 273/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1396 - val_loss: 0.5575\n",
      "Epoch 274/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.6078\n",
      "Epoch 275/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1302 - val_loss: 0.6254\n",
      "Epoch 276/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.5919\n",
      "Epoch 277/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1066 - val_loss: 0.6303\n",
      "Epoch 278/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2373 - val_loss: 0.6953\n",
      "Epoch 279/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3526 - val_loss: 0.5832\n",
      "Epoch 280/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4121 - val_loss: 0.8803\n",
      "Epoch 281/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3068 - val_loss: 0.8475\n",
      "Epoch 282/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2146 - val_loss: 0.6689\n",
      "Epoch 283/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1688 - val_loss: 0.6261\n",
      "Epoch 284/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1752 - val_loss: 0.7168\n",
      "Epoch 285/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.6039\n",
      "Epoch 286/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1752 - val_loss: 0.6521\n",
      "Epoch 287/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1977 - val_loss: 0.7191\n",
      "Epoch 288/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1999 - val_loss: 0.6792\n",
      "Epoch 289/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1442 - val_loss: 0.6002\n",
      "Epoch 290/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1325 - val_loss: 0.6210\n",
      "Epoch 291/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1728 - val_loss: 0.8489\n",
      "Epoch 292/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1578 - val_loss: 0.6823\n",
      "Epoch 293/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1973 - val_loss: 0.5836\n",
      "Epoch 294/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2652 - val_loss: 0.5921\n",
      "Epoch 295/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2821 - val_loss: 0.8014\n",
      "Epoch 296/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2148 - val_loss: 0.7383\n",
      "Epoch 297/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1744 - val_loss: 0.6162\n",
      "Epoch 298/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1203 - val_loss: 0.5903\n",
      "Epoch 299/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1232 - val_loss: 0.6879\n",
      "Epoch 300/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1570 - val_loss: 0.6434\n",
      "Epoch 301/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1049 - val_loss: 0.5251\n",
      "Epoch 302/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.6664\n",
      "Epoch 303/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2335 - val_loss: 0.9901\n",
      "Epoch 304/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3073 - val_loss: 0.6395\n",
      "Epoch 305/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1741 - val_loss: 0.6365\n",
      "Epoch 306/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1314 - val_loss: 0.5834\n",
      "Epoch 307/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1185 - val_loss: 0.6514\n",
      "Epoch 308/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1065 - val_loss: 0.5978\n",
      "Epoch 309/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2350 - val_loss: 0.5448\n",
      "Epoch 310/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2159 - val_loss: 0.6456\n",
      "Epoch 311/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2452 - val_loss: 0.6160\n",
      "Epoch 312/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1495 - val_loss: 0.6846\n",
      "Epoch 313/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1085 - val_loss: 0.6180\n",
      "Epoch 314/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1477 - val_loss: 0.6203\n",
      "Epoch 315/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2078 - val_loss: 0.5398\n",
      "Epoch 316/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2136 - val_loss: 0.6538\n",
      "Epoch 317/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2448 - val_loss: 0.7469\n",
      "Epoch 318/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2690 - val_loss: 0.8084\n",
      "Epoch 319/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1407 - val_loss: 0.6582\n",
      "Epoch 320/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.6940\n",
      "Epoch 321/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1341 - val_loss: 0.6884\n",
      "Epoch 322/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2437 - val_loss: 0.7428\n",
      "Epoch 323/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1665 - val_loss: 0.7295\n",
      "Epoch 324/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3479 - val_loss: 0.8514\n",
      "Epoch 325/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3024 - val_loss: 1.0693\n",
      "Epoch 326/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3128 - val_loss: 1.1921\n",
      "Epoch 327/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3157 - val_loss: 0.6166\n",
      "Epoch 328/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2837 - val_loss: 0.6395\n",
      "Epoch 329/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2791 - val_loss: 0.5654\n",
      "Epoch 330/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2247 - val_loss: 0.5931\n",
      "Epoch 331/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2738 - val_loss: 0.6931\n",
      "Epoch 332/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1234 - val_loss: 0.5634\n",
      "Epoch 333/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1365 - val_loss: 0.7829\n",
      "Epoch 334/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2129 - val_loss: 0.7120\n",
      "Epoch 335/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1549 - val_loss: 0.7084\n",
      "Epoch 336/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1497 - val_loss: 0.6353\n",
      "Epoch 337/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1579 - val_loss: 0.6063\n",
      "Epoch 338/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.5733\n",
      "Epoch 339/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1555 - val_loss: 0.5439\n",
      "Epoch 340/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1155 - val_loss: 0.5801\n",
      "Epoch 341/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1477 - val_loss: 0.6100\n",
      "Epoch 342/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1258 - val_loss: 0.5427\n",
      "Epoch 343/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2107 - val_loss: 1.0105\n",
      "Epoch 344/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1555 - val_loss: 0.4746\n",
      "Epoch 345/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1054 - val_loss: 0.5262\n",
      "Epoch 346/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1954 - val_loss: 1.0139\n",
      "Epoch 347/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2867 - val_loss: 0.8224\n",
      "Epoch 348/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2275 - val_loss: 0.6567\n",
      "Epoch 349/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1301 - val_loss: 0.7031\n",
      "Epoch 350/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.6128\n",
      "Epoch 351/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0907 - val_loss: 0.5598\n",
      "Epoch 352/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1161 - val_loss: 0.6838\n",
      "Epoch 353/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1694 - val_loss: 0.6937\n",
      "Epoch 354/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2115 - val_loss: 0.8450\n",
      "Epoch 355/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1937 - val_loss: 0.9134\n",
      "Epoch 356/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1595 - val_loss: 0.6189\n",
      "Epoch 357/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1724 - val_loss: 0.5985\n",
      "Epoch 358/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2608 - val_loss: 0.6648\n",
      "Epoch 359/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1851 - val_loss: 0.6513\n",
      "Epoch 360/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1558 - val_loss: 0.7160\n",
      "Epoch 361/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2215 - val_loss: 0.7672\n",
      "Epoch 362/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.7990\n",
      "Epoch 363/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1669 - val_loss: 0.7600\n",
      "Epoch 364/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1848 - val_loss: 0.5832\n",
      "Epoch 365/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1847 - val_loss: 0.6694\n",
      "Epoch 366/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 0.6175\n",
      "Epoch 367/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.6478\n",
      "Epoch 368/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1254 - val_loss: 0.6410\n",
      "Epoch 369/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1104 - val_loss: 0.6009\n",
      "Epoch 370/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0970 - val_loss: 0.5412\n",
      "Epoch 371/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.8527\n",
      "Epoch 372/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1115 - val_loss: 0.6178\n",
      "Epoch 373/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1162 - val_loss: 0.6716\n",
      "Epoch 374/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1499 - val_loss: 0.7785\n",
      "Epoch 375/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1631 - val_loss: 0.6762\n",
      "Epoch 376/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1682 - val_loss: 0.7392\n",
      "Epoch 377/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1359 - val_loss: 0.6166\n",
      "Epoch 378/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1019 - val_loss: 0.6032\n",
      "Epoch 379/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1630 - val_loss: 0.8046\n",
      "Epoch 380/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1652 - val_loss: 0.5870\n",
      "Epoch 381/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0994 - val_loss: 0.5801\n",
      "Epoch 382/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1232 - val_loss: 0.5814\n",
      "Epoch 383/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1497 - val_loss: 0.6539\n",
      "Epoch 384/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 0.6438\n",
      "Epoch 385/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2589 - val_loss: 1.0075\n",
      "Epoch 386/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1091 - val_loss: 2.1859\n",
      "Epoch 387/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8817 - val_loss: 0.8736\n",
      "Epoch 388/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5009 - val_loss: 0.9007\n",
      "Epoch 389/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3649 - val_loss: 0.7609\n",
      "Epoch 390/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2713 - val_loss: 0.7070\n",
      "Epoch 391/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2731 - val_loss: 0.5520\n",
      "Epoch 392/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2928 - val_loss: 0.7550\n",
      "Epoch 393/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3172 - val_loss: 0.9543\n",
      "Epoch 394/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4885 - val_loss: 1.0406\n",
      "Epoch 395/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4706 - val_loss: 1.1041\n",
      "Epoch 396/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3433 - val_loss: 0.9257\n",
      "Epoch 397/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3147 - val_loss: 0.6632\n",
      "Epoch 398/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2061 - val_loss: 0.6258\n",
      "Epoch 399/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1731 - val_loss: 0.7492\n",
      "Epoch 400/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2815 - val_loss: 1.1414\n",
      "Epoch 401/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2775 - val_loss: 0.7482\n",
      "Epoch 402/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5622 - val_loss: 1.0101\n",
      "Epoch 403/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.6741\n",
      "Epoch 404/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2058 - val_loss: 0.6115\n",
      "Epoch 405/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1916 - val_loss: 0.5792\n",
      "Epoch 406/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2101 - val_loss: 0.6258\n",
      "Epoch 407/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2170 - val_loss: 0.6318\n",
      "Epoch 408/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1980 - val_loss: 0.7419\n",
      "Epoch 409/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4177 - val_loss: 1.3183\n",
      "Epoch 410/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5882 - val_loss: 1.4779\n",
      "Epoch 411/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.6410\n",
      "Epoch 412/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 1.2392\n",
      "Epoch 413/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3138 - val_loss: 0.6232\n",
      "Epoch 414/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2248 - val_loss: 0.5961\n",
      "Epoch 415/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4609 - val_loss: 1.0258\n",
      "Epoch 416/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5435 - val_loss: 0.8749\n",
      "Epoch 417/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5633 - val_loss: 0.8705\n",
      "Epoch 418/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.7556\n",
      "Epoch 419/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1910 - val_loss: 0.7524\n",
      "Epoch 420/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1634 - val_loss: 0.6399\n",
      "Epoch 421/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1743 - val_loss: 0.6253\n",
      "Epoch 422/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1630 - val_loss: 0.7387\n",
      "Epoch 423/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2004 - val_loss: 0.6735\n",
      "Epoch 424/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2162 - val_loss: 0.6341\n",
      "Epoch 425/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.5826\n",
      "Epoch 426/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1335 - val_loss: 0.6450\n",
      "Epoch 427/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1281 - val_loss: 0.5820\n",
      "Epoch 428/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1409 - val_loss: 0.6803\n",
      "Epoch 429/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1550 - val_loss: 0.6016\n",
      "Epoch 430/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1365 - val_loss: 0.5980\n",
      "Epoch 431/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1638 - val_loss: 0.5889\n",
      "Epoch 432/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1407 - val_loss: 0.5878\n",
      "Epoch 433/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1466 - val_loss: 0.6717\n",
      "Epoch 434/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1978 - val_loss: 0.7397\n",
      "Epoch 435/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1917 - val_loss: 0.6545\n",
      "Epoch 436/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.6188\n",
      "Epoch 437/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1271 - val_loss: 0.6744\n",
      "Epoch 438/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1148 - val_loss: 0.5891\n",
      "Epoch 439/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1730 - val_loss: 0.7709\n",
      "Epoch 440/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2178 - val_loss: 0.6448\n",
      "Epoch 441/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1200 - val_loss: 0.6307\n",
      "Epoch 442/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1618 - val_loss: 0.5653\n",
      "Epoch 443/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1362 - val_loss: 0.6481\n",
      "Epoch 444/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1784 - val_loss: 0.7735\n",
      "Epoch 445/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1923 - val_loss: 0.7674\n",
      "Epoch 446/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1186 - val_loss: 0.5936\n",
      "Epoch 447/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1131 - val_loss: 0.6593\n",
      "Epoch 448/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1738 - val_loss: 0.6822\n",
      "Epoch 449/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1683 - val_loss: 0.7623\n",
      "Epoch 450/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1737 - val_loss: 0.6662\n",
      "Epoch 451/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1746 - val_loss: 0.5825\n",
      "Epoch 452/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1431 - val_loss: 0.6113\n",
      "Epoch 453/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1259 - val_loss: 0.5770\n",
      "Epoch 454/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1162 - val_loss: 0.6635\n",
      "Epoch 455/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1254 - val_loss: 0.6050\n",
      "Epoch 456/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1216 - val_loss: 0.5951\n",
      "Epoch 457/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.6423\n",
      "Epoch 458/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1334 - val_loss: 0.5788\n",
      "Epoch 459/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1410 - val_loss: 0.7828\n",
      "Epoch 460/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1588 - val_loss: 0.5730\n",
      "Epoch 461/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.6197\n",
      "Epoch 462/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1476 - val_loss: 0.7663\n",
      "Epoch 463/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1197 - val_loss: 0.6302\n",
      "Epoch 464/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0994 - val_loss: 0.5960\n",
      "Epoch 465/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1299 - val_loss: 0.5805\n",
      "Epoch 466/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1612 - val_loss: 0.6032\n",
      "Epoch 467/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1299 - val_loss: 0.5997\n",
      "Epoch 468/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.5990\n",
      "Epoch 469/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1435 - val_loss: 0.8344\n",
      "Epoch 470/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2087 - val_loss: 1.0678\n",
      "Epoch 471/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3124 - val_loss: 1.1235\n",
      "Epoch 472/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2477 - val_loss: 0.6740\n",
      "Epoch 473/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1354 - val_loss: 0.6362\n",
      "Epoch 474/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1065 - val_loss: 0.6312\n",
      "Epoch 475/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1554 - val_loss: 0.6977\n",
      "Epoch 476/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2041 - val_loss: 0.6371\n",
      "Epoch 477/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1761 - val_loss: 0.7167\n",
      "Epoch 478/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2023 - val_loss: 0.7161\n",
      "Epoch 479/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1368 - val_loss: 0.5937\n",
      "Epoch 480/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1124 - val_loss: 0.6450\n",
      "Epoch 481/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1087 - val_loss: 0.6120\n",
      "Epoch 482/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1290 - val_loss: 0.6289\n",
      "Epoch 483/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1485 - val_loss: 0.6319\n",
      "Epoch 484/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1184 - val_loss: 0.6104\n",
      "Epoch 485/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1286 - val_loss: 0.6630\n",
      "Epoch 486/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1447 - val_loss: 0.6180\n",
      "Epoch 487/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1059 - val_loss: 0.6996\n",
      "Epoch 488/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1472 - val_loss: 0.5813\n",
      "Epoch 489/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1055 - val_loss: 0.5763\n",
      "Epoch 490/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1597 - val_loss: 0.6971\n",
      "Epoch 491/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1621 - val_loss: 0.5876\n",
      "Epoch 492/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1618 - val_loss: 0.6333\n",
      "Epoch 493/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1342 - val_loss: 0.5605\n",
      "Epoch 494/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.5137\n",
      "Epoch 495/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5174 - val_loss: 0.6495\n",
      "Epoch 496/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3043 - val_loss: 0.8583\n",
      "Epoch 497/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3729 - val_loss: 0.7423\n",
      "Epoch 498/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2461 - val_loss: 0.7592\n",
      "Epoch 499/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1552 - val_loss: 0.6532\n",
      "Epoch 500/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1077 - val_loss: 0.7203\n",
      "Epoch 501/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1232 - val_loss: 0.6865\n",
      "Epoch 502/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1255 - val_loss: 0.6278\n",
      "Epoch 503/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1190 - val_loss: 0.6618\n",
      "Epoch 504/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1070 - val_loss: 0.6939\n",
      "Epoch 505/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1861 - val_loss: 0.7318\n",
      "Epoch 506/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2521 - val_loss: 0.6848\n",
      "Epoch 507/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2308 - val_loss: 0.6263\n",
      "Epoch 508/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1395 - val_loss: 0.6658\n",
      "Epoch 509/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.5902\n",
      "Epoch 510/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1222 - val_loss: 0.5932\n",
      "Epoch 511/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1514 - val_loss: 0.7261\n",
      "Epoch 512/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2120 - val_loss: 0.7095\n",
      "Epoch 513/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2284 - val_loss: 0.6475\n",
      "Epoch 514/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1529 - val_loss: 0.8092\n",
      "Epoch 515/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.8794\n",
      "Epoch 516/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4335 - val_loss: 0.7360\n",
      "Epoch 517/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3394 - val_loss: 0.8589\n",
      "Epoch 518/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2324 - val_loss: 0.7071\n",
      "Epoch 519/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1225 - val_loss: 0.7078\n",
      "Epoch 520/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.7019\n",
      "Epoch 521/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1378 - val_loss: 0.6065\n",
      "Epoch 522/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1878 - val_loss: 1.0026\n",
      "Epoch 523/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2345 - val_loss: 0.6298\n",
      "Epoch 524/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1111 - val_loss: 0.5532\n",
      "Epoch 525/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1095 - val_loss: 0.5263\n",
      "Epoch 526/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1105 - val_loss: 0.6293\n",
      "Epoch 527/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.5985\n",
      "Epoch 528/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1483 - val_loss: 0.5528\n",
      "Epoch 529/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1141 - val_loss: 0.5611\n",
      "Epoch 530/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.6373\n",
      "Epoch 531/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.5267\n",
      "Epoch 532/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1470 - val_loss: 0.5222\n",
      "Epoch 533/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1151 - val_loss: 0.5349\n",
      "Epoch 534/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1048 - val_loss: 0.5627\n",
      "Epoch 535/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1553 - val_loss: 0.6216\n",
      "Epoch 536/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1348 - val_loss: 0.5710\n",
      "Epoch 537/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1797 - val_loss: 0.6515\n",
      "Epoch 538/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3136 - val_loss: 0.6755\n",
      "Epoch 539/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2174 - val_loss: 0.7937\n",
      "Epoch 540/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2821 - val_loss: 0.7831\n",
      "Epoch 541/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1866 - val_loss: 0.5456\n",
      "Epoch 542/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1322 - val_loss: 0.6484\n",
      "Epoch 543/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.6236\n",
      "Epoch 544/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0957 - val_loss: 0.5323\n",
      "Epoch 545/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1680 - val_loss: 0.6629\n",
      "Epoch 546/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1518 - val_loss: 0.5990\n",
      "Epoch 547/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0897 - val_loss: 0.5719\n",
      "Epoch 548/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1117 - val_loss: 0.5549\n",
      "Epoch 549/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0915 - val_loss: 0.5248\n",
      "Epoch 550/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0929 - val_loss: 0.5316\n",
      "Epoch 551/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.7080\n",
      "Epoch 552/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1417 - val_loss: 0.5139\n",
      "Epoch 553/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1219 - val_loss: 0.5610\n",
      "Epoch 554/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.5362\n",
      "Epoch 555/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0911 - val_loss: 0.5518\n",
      "Epoch 556/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.5623\n",
      "Epoch 557/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.5261\n",
      "Epoch 558/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1032 - val_loss: 0.6155\n",
      "Epoch 559/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0841 - val_loss: 0.5699\n",
      "Epoch 560/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.5751\n",
      "Epoch 561/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1165 - val_loss: 0.7164\n",
      "Epoch 562/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2744 - val_loss: 0.5414\n",
      "Epoch 563/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1797 - val_loss: 0.6294\n",
      "Epoch 564/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1112 - val_loss: 0.6820\n",
      "Epoch 565/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1713 - val_loss: 1.0046\n",
      "Epoch 566/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2086 - val_loss: 1.0360\n",
      "Epoch 567/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1943 - val_loss: 0.5109\n",
      "Epoch 568/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1235 - val_loss: 0.6111\n",
      "Epoch 569/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.5268\n",
      "Epoch 570/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 0.5011\n",
      "Epoch 571/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.6648\n",
      "Epoch 572/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.4325\n",
      "Epoch 573/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1037 - val_loss: 0.5416\n",
      "Epoch 574/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.5291\n",
      "Epoch 575/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.5330\n",
      "Epoch 576/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.5525\n",
      "Epoch 577/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.4600\n",
      "Epoch 578/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.5294\n",
      "Epoch 579/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.5815\n",
      "Epoch 580/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1573 - val_loss: 0.6756\n",
      "Epoch 581/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2039 - val_loss: 0.6386\n",
      "Epoch 582/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1070 - val_loss: 0.5115\n",
      "Epoch 583/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1256 - val_loss: 0.5485\n",
      "Epoch 584/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1390 - val_loss: 0.5367\n",
      "Epoch 585/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.5405\n",
      "Epoch 586/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.5726\n",
      "Epoch 587/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.5090\n",
      "Epoch 588/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0992 - val_loss: 0.5622\n",
      "Epoch 589/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1248 - val_loss: 0.5352\n",
      "Epoch 590/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.5209\n",
      "Epoch 591/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1574 - val_loss: 0.5655\n",
      "Epoch 592/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.5261\n",
      "Epoch 593/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1291 - val_loss: 0.6523\n",
      "Epoch 594/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1319 - val_loss: 0.6759\n",
      "Epoch 595/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2374 - val_loss: 0.5955\n",
      "Epoch 596/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2043 - val_loss: 0.6775\n",
      "Epoch 597/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2024 - val_loss: 0.5592\n",
      "Epoch 598/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1327 - val_loss: 0.5606\n",
      "Epoch 599/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0953 - val_loss: 0.5428\n",
      "Epoch 600/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.5508\n",
      "Epoch 601/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.5559\n",
      "Epoch 602/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1103 - val_loss: 0.5219\n",
      "Epoch 603/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1210 - val_loss: 0.5828\n",
      "Epoch 604/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.5580\n",
      "Epoch 605/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.5323\n",
      "Epoch 606/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1897 - val_loss: 0.5797\n",
      "Epoch 607/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2384 - val_loss: 0.9025\n",
      "Epoch 608/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2279 - val_loss: 0.5371\n",
      "Epoch 609/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1067 - val_loss: 0.5249\n",
      "Epoch 610/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0859 - val_loss: 0.5126\n",
      "Epoch 611/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0927 - val_loss: 0.5497\n",
      "Epoch 612/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0845 - val_loss: 0.6328\n",
      "Epoch 613/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1483 - val_loss: 0.5673\n",
      "Epoch 614/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1326 - val_loss: 0.5433\n",
      "Epoch 615/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1649 - val_loss: 0.5827\n",
      "Epoch 616/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0993 - val_loss: 0.6114\n",
      "Epoch 617/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.5642\n",
      "Epoch 618/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.5529\n",
      "Epoch 619/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.4945\n",
      "Epoch 620/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1025 - val_loss: 0.6806\n",
      "Epoch 621/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2202 - val_loss: 0.5939\n",
      "Epoch 622/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1057 - val_loss: 0.5184\n",
      "Epoch 623/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.5581\n",
      "Epoch 624/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0914 - val_loss: 0.4373\n",
      "Epoch 625/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.4547\n",
      "Epoch 626/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.5733\n",
      "Epoch 627/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.5107\n",
      "Epoch 628/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.5963\n",
      "Epoch 629/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0902 - val_loss: 0.4839\n",
      "Epoch 630/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.5227\n",
      "Epoch 631/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.5540\n",
      "Epoch 632/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.4424\n",
      "Epoch 633/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.4889\n",
      "Epoch 634/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.4817\n",
      "Epoch 635/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0914 - val_loss: 0.5119\n",
      "Epoch 636/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1731 - val_loss: 0.6835\n",
      "Epoch 637/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1553 - val_loss: 0.4962\n",
      "Epoch 638/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.4905\n",
      "Epoch 639/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.5327\n",
      "Epoch 640/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.5071\n",
      "Epoch 641/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1036 - val_loss: 0.5029\n",
      "Epoch 642/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1093 - val_loss: 0.5847\n",
      "Epoch 643/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1113 - val_loss: 0.5192\n",
      "Epoch 644/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.5725\n",
      "Epoch 645/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 0.4874\n",
      "Epoch 646/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.6017\n",
      "Epoch 647/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0988 - val_loss: 0.6220\n",
      "Epoch 648/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1473 - val_loss: 0.5768\n",
      "Epoch 649/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.4927\n",
      "Epoch 650/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.5060\n",
      "Epoch 651/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.5354\n",
      "Epoch 652/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.5707\n",
      "Epoch 653/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1091 - val_loss: 0.6129\n",
      "Epoch 654/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1366 - val_loss: 0.5158\n",
      "Epoch 655/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.4815\n",
      "Epoch 656/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0846 - val_loss: 0.4936\n",
      "Epoch 657/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.5115\n",
      "Epoch 658/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.4619\n",
      "Epoch 659/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0993 - val_loss: 0.5112\n",
      "Epoch 660/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.5605\n",
      "Epoch 661/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.5282\n",
      "Epoch 662/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.5005\n",
      "Epoch 663/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.5402\n",
      "Epoch 664/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.4946\n",
      "Epoch 665/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.5626\n",
      "Epoch 666/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.4891\n",
      "Epoch 667/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0959 - val_loss: 0.5008\n",
      "Epoch 668/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.5107\n",
      "Epoch 669/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.5042\n",
      "Epoch 670/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.4999\n",
      "Epoch 671/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1267 - val_loss: 0.5845\n",
      "Epoch 672/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1230 - val_loss: 0.5045\n",
      "Epoch 673/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.5741\n",
      "Epoch 674/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.5369\n",
      "Epoch 675/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.6532\n",
      "Epoch 676/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1322 - val_loss: 0.7552\n",
      "Epoch 677/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1460 - val_loss: 0.5912\n",
      "Epoch 678/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.4950\n",
      "Epoch 679/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1393 - val_loss: 0.4942\n",
      "Epoch 680/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1616 - val_loss: 0.5138\n",
      "Epoch 681/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1132 - val_loss: 0.5298\n",
      "Epoch 682/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.4999\n",
      "Epoch 683/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.6250\n",
      "Epoch 684/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1298 - val_loss: 0.5214\n",
      "Epoch 685/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.5230\n",
      "Epoch 686/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.4669\n",
      "Epoch 687/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.6886\n",
      "Epoch 688/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1465 - val_loss: 0.6422\n",
      "Epoch 689/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1106 - val_loss: 0.5451\n",
      "Epoch 690/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.6070\n",
      "Epoch 691/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.5333\n",
      "Epoch 692/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.5177\n",
      "Epoch 693/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.5730\n",
      "Epoch 694/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.5504\n",
      "Epoch 695/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1238 - val_loss: 0.6202\n",
      "Epoch 696/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.6042\n",
      "Epoch 697/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1466 - val_loss: 0.6107\n",
      "Epoch 698/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1557 - val_loss: 0.7623\n",
      "Epoch 699/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1170 - val_loss: 0.6438\n",
      "Epoch 700/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.5021\n",
      "Epoch 701/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.4901\n",
      "Epoch 702/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1369 - val_loss: 0.4702\n",
      "Epoch 703/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1039 - val_loss: 0.4844\n",
      "Epoch 704/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0976 - val_loss: 0.5198\n",
      "Epoch 705/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.5048\n",
      "Epoch 706/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.4698\n",
      "Epoch 707/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.5304\n",
      "Epoch 708/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1014 - val_loss: 0.5443\n",
      "Epoch 709/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.4908\n",
      "Epoch 710/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.4957\n",
      "Epoch 711/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.5835\n",
      "Epoch 712/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.5310\n",
      "Epoch 713/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1008 - val_loss: 0.4563\n",
      "Epoch 714/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0903 - val_loss: 0.4799\n",
      "Epoch 715/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0893 - val_loss: 0.4476\n",
      "Epoch 716/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.5327\n",
      "Epoch 717/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.4837\n",
      "Epoch 718/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.5169\n",
      "Epoch 719/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.5613\n",
      "Epoch 720/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.5081\n",
      "Epoch 721/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1090 - val_loss: 0.5134\n",
      "Epoch 722/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2642 - val_loss: 0.5818\n",
      "Epoch 723/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2240 - val_loss: 0.7806\n",
      "Epoch 724/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.5157\n",
      "Epoch 725/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.4957\n",
      "Epoch 726/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1055 - val_loss: 0.5023\n",
      "Epoch 727/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.5029\n",
      "Epoch 728/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2636 - val_loss: 0.7937\n",
      "Epoch 729/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2246 - val_loss: 0.5315\n",
      "Epoch 730/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1783 - val_loss: 0.7353\n",
      "Epoch 731/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1079 - val_loss: 0.5777\n",
      "Epoch 732/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1326 - val_loss: 0.7548\n",
      "Epoch 733/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.5800\n",
      "Epoch 734/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.5153\n",
      "Epoch 735/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.6729\n",
      "Epoch 736/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0903 - val_loss: 0.4650\n",
      "Epoch 737/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.5132\n",
      "Epoch 738/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0961 - val_loss: 0.5301\n",
      "Epoch 739/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.6191\n",
      "Epoch 740/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.5790\n",
      "Epoch 741/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.5468\n",
      "Epoch 742/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1148 - val_loss: 0.5768\n",
      "Epoch 743/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.5415\n",
      "Epoch 744/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.5502\n",
      "Epoch 745/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.5757\n",
      "Epoch 746/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.5515\n",
      "Epoch 747/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.5226\n",
      "Epoch 748/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.5310\n",
      "Epoch 749/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1100 - val_loss: 0.5689\n",
      "Epoch 750/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2056 - val_loss: 0.7233\n",
      "Epoch 751/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1689 - val_loss: 0.7870\n",
      "Epoch 752/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1673 - val_loss: 0.4328\n",
      "Epoch 753/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.5332\n",
      "Epoch 754/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0932 - val_loss: 0.5321\n",
      "Epoch 755/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0981 - val_loss: 0.6077\n",
      "Epoch 756/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1067 - val_loss: 0.5199\n",
      "Epoch 757/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.5148\n",
      "Epoch 758/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.4595\n",
      "Epoch 759/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.4846\n",
      "Epoch 760/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1274 - val_loss: 0.5557\n",
      "Epoch 761/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.5814\n",
      "Epoch 762/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0916 - val_loss: 0.4661\n",
      "Epoch 763/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0924 - val_loss: 0.5164\n",
      "Epoch 764/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1273 - val_loss: 0.5520\n",
      "Epoch 765/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.5500\n",
      "Epoch 766/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.5817\n",
      "Epoch 767/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.4518\n",
      "Epoch 768/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.5040\n",
      "Epoch 769/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0822 - val_loss: 0.4449\n",
      "Epoch 770/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.4615\n",
      "Epoch 771/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.4542\n",
      "Epoch 772/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.5136\n",
      "Epoch 773/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.4275\n",
      "Epoch 774/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.5009\n",
      "Epoch 775/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.4448\n",
      "Epoch 776/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.4519\n",
      "Epoch 777/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.4931\n",
      "Epoch 778/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.5024\n",
      "Epoch 779/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.5491\n",
      "Epoch 780/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.4838\n",
      "Epoch 781/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0897 - val_loss: 0.5358\n",
      "Epoch 782/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.5316\n",
      "Epoch 783/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1077 - val_loss: 0.4892\n",
      "Epoch 784/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0839 - val_loss: 0.5173\n",
      "Epoch 785/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.4781\n",
      "Epoch 786/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.5156\n",
      "Epoch 787/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1058 - val_loss: 0.4360\n",
      "Epoch 788/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.5390\n",
      "Epoch 789/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0917 - val_loss: 0.5620\n",
      "Epoch 790/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1077 - val_loss: 0.4985\n",
      "Epoch 791/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.4209\n",
      "Epoch 792/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.5241\n",
      "Epoch 793/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.4363\n",
      "Epoch 794/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.4489\n",
      "Epoch 795/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.5011\n",
      "Epoch 796/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.4183\n",
      "Epoch 797/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.5302\n",
      "Epoch 798/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.4474\n",
      "Epoch 799/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.4330\n",
      "Epoch 800/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0933 - val_loss: 0.4396\n",
      "Epoch 801/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.5036\n",
      "Epoch 802/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1106 - val_loss: 0.6291\n",
      "Epoch 803/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1333 - val_loss: 0.6731\n",
      "Epoch 804/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.7472\n",
      "Epoch 805/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2330 - val_loss: 0.3906\n",
      "Epoch 806/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2108 - val_loss: 0.5607\n",
      "Epoch 807/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.5552\n",
      "Epoch 808/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.6407\n",
      "Epoch 809/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0960 - val_loss: 0.5264\n",
      "Epoch 810/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.5255\n",
      "Epoch 811/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.5405\n",
      "Epoch 812/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.4874\n",
      "Epoch 813/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.5126\n",
      "Epoch 814/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.5141\n",
      "Epoch 815/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.4897\n",
      "Epoch 816/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.4630\n",
      "Epoch 817/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.4777\n",
      "Epoch 818/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.5479\n",
      "Epoch 819/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.5155\n",
      "Epoch 820/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.5688\n",
      "Epoch 821/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1362 - val_loss: 0.7509\n",
      "Epoch 822/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2063 - val_loss: 0.6706\n",
      "Epoch 823/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1993 - val_loss: 0.5972\n",
      "Epoch 824/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1740 - val_loss: 0.5541\n",
      "Epoch 825/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0995 - val_loss: 0.6144\n",
      "Epoch 826/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.5658\n",
      "Epoch 827/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1128 - val_loss: 0.5942\n",
      "Epoch 828/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1322 - val_loss: 0.4762\n",
      "Epoch 829/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1126 - val_loss: 0.5507\n",
      "Epoch 830/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.4430\n",
      "Epoch 831/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1194 - val_loss: 0.4709\n",
      "Epoch 832/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1245 - val_loss: 0.4884\n",
      "Epoch 833/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.4704\n",
      "Epoch 834/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1033 - val_loss: 0.5184\n",
      "Epoch 835/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.4521\n",
      "Epoch 836/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.5067\n",
      "Epoch 837/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.4762\n",
      "Epoch 838/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.5516\n",
      "Epoch 839/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.5224\n",
      "Epoch 840/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.5139\n",
      "Epoch 841/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1125 - val_loss: 0.4733\n",
      "Epoch 842/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1152 - val_loss: 0.4620\n",
      "Epoch 843/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.4528\n",
      "Epoch 844/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.4758\n",
      "Epoch 845/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0905 - val_loss: 0.7044\n",
      "Epoch 846/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1693 - val_loss: 0.4881\n",
      "Epoch 847/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.5163\n",
      "Epoch 848/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0932 - val_loss: 0.4965\n",
      "Epoch 849/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.4180\n",
      "Epoch 850/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.4818\n",
      "Epoch 851/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.5193\n",
      "Epoch 852/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.4861\n",
      "Epoch 853/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.4677\n",
      "Epoch 854/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.4719\n",
      "Epoch 855/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.4727\n",
      "Epoch 856/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.4915\n",
      "Epoch 857/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1138 - val_loss: 0.5681\n",
      "Epoch 858/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1077 - val_loss: 0.5269\n",
      "Epoch 859/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0813 - val_loss: 0.6756\n",
      "Epoch 860/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1566 - val_loss: 0.8372\n",
      "Epoch 861/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2147 - val_loss: 0.6242\n",
      "Epoch 862/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1247 - val_loss: 0.6576\n",
      "Epoch 863/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1340 - val_loss: 0.5458\n",
      "Epoch 864/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.5432\n",
      "Epoch 865/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.6012\n",
      "Epoch 866/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1098 - val_loss: 0.9681\n",
      "Epoch 867/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2877 - val_loss: 0.8532\n",
      "Epoch 868/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2447 - val_loss: 0.6473\n",
      "Epoch 869/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1764 - val_loss: 0.6292\n",
      "Epoch 870/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0954 - val_loss: 0.6324\n",
      "Epoch 871/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.6274\n",
      "Epoch 872/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.5371\n",
      "Epoch 873/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.5122\n",
      "Epoch 874/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.5688\n",
      "Epoch 875/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.5232\n",
      "Epoch 876/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.5640\n",
      "Epoch 877/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.5283\n",
      "Epoch 878/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.5352\n",
      "Epoch 879/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.5313\n",
      "Epoch 880/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.5469\n",
      "Epoch 881/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.5723\n",
      "Epoch 882/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.5346\n",
      "Epoch 883/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.4928\n",
      "Epoch 884/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.5598\n",
      "Epoch 885/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.5832\n",
      "Epoch 886/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1577 - val_loss: 0.5426\n",
      "Epoch 887/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1603 - val_loss: 0.4487\n",
      "Epoch 888/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 0.5368\n",
      "Epoch 889/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.5157\n",
      "Epoch 890/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.5307\n",
      "Epoch 891/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.5150\n",
      "Epoch 892/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.5334\n",
      "Epoch 893/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.4980\n",
      "Epoch 894/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.5361\n",
      "Epoch 895/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.4253\n",
      "Epoch 896/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.5423\n",
      "Epoch 897/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.4874\n",
      "Epoch 898/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0600 - val_loss: 0.5342\n",
      "Epoch 899/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.4972\n",
      "Epoch 900/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.5725\n",
      "Epoch 901/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.5606\n",
      "Epoch 902/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.5942\n",
      "Epoch 903/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.5393\n",
      "Epoch 904/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.5081\n",
      "Epoch 905/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.5547\n",
      "Epoch 906/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.4680\n",
      "Epoch 907/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.5462\n",
      "Epoch 908/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.5139\n",
      "Epoch 909/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.4765\n",
      "Epoch 910/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.5581\n",
      "Epoch 911/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.4900\n",
      "Epoch 912/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.5670\n",
      "Epoch 913/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.5048\n",
      "Epoch 914/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.5565\n",
      "Epoch 915/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.5385\n",
      "Epoch 916/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.5847\n",
      "Epoch 917/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.4743\n",
      "Epoch 918/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.5662\n",
      "Epoch 919/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.4949\n",
      "Epoch 920/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.5787\n",
      "Epoch 921/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0702 - val_loss: 0.5647\n",
      "Epoch 922/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.4819\n",
      "Epoch 923/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.5003\n",
      "Epoch 924/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.5739\n",
      "Epoch 925/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1132 - val_loss: 0.6255\n",
      "Epoch 926/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1181 - val_loss: 0.8050\n",
      "Epoch 927/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2149 - val_loss: 0.7656\n",
      "Epoch 928/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2562 - val_loss: 0.9845\n",
      "Epoch 929/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1334 - val_loss: 0.4112\n",
      "Epoch 930/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.5116\n",
      "Epoch 931/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0859 - val_loss: 0.6112\n",
      "Epoch 932/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.6274\n",
      "Epoch 933/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1355 - val_loss: 0.5466\n",
      "Epoch 934/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.5050\n",
      "Epoch 935/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.5082\n",
      "Epoch 936/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.5477\n",
      "Epoch 937/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.6181\n",
      "Epoch 938/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1222 - val_loss: 0.6157\n",
      "Epoch 939/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1287 - val_loss: 0.6119\n",
      "Epoch 940/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.6721\n",
      "Epoch 941/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.6006\n",
      "Epoch 942/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.5595\n",
      "Epoch 943/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0994 - val_loss: 0.5336\n",
      "Epoch 944/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0574 - val_loss: 0.4564\n",
      "Epoch 945/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0831 - val_loss: 0.4588\n",
      "Epoch 946/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.5077\n",
      "Epoch 947/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.5163\n",
      "Epoch 948/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.6878\n",
      "Epoch 949/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1596 - val_loss: 0.8837\n",
      "Epoch 950/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2428 - val_loss: 0.8316\n",
      "Epoch 951/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1997 - val_loss: 0.6125\n",
      "Epoch 952/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2073 - val_loss: 0.7577\n",
      "Epoch 953/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1399 - val_loss: 0.5733\n",
      "Epoch 954/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0655 - val_loss: 0.5728\n",
      "Epoch 955/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.5272\n",
      "Epoch 956/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.5253\n",
      "Epoch 957/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.4847\n",
      "Epoch 958/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.4978\n",
      "Epoch 959/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.5414\n",
      "Epoch 960/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.5940\n",
      "Epoch 961/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.5763\n",
      "Epoch 962/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.5273\n",
      "Epoch 963/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.5189\n",
      "Epoch 964/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0947 - val_loss: 0.5909\n",
      "Epoch 965/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.6957\n",
      "Epoch 966/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1113 - val_loss: 0.4274\n",
      "Epoch 967/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.5694\n",
      "Epoch 968/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.4270\n",
      "Epoch 969/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.4881\n",
      "Epoch 970/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.4805\n",
      "Epoch 971/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.4847\n",
      "Epoch 972/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.5404\n",
      "Epoch 973/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.4430\n",
      "Epoch 974/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.5003\n",
      "Epoch 975/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.4505\n",
      "Epoch 976/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.5437\n",
      "Epoch 977/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0448 - val_loss: 0.5593\n",
      "Epoch 978/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.5001\n",
      "Epoch 979/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0924 - val_loss: 0.5427\n",
      "Epoch 980/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.5331\n",
      "Epoch 981/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.8849\n",
      "Epoch 982/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2210 - val_loss: 0.7165\n",
      "Epoch 983/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1135 - val_loss: 0.4661\n",
      "Epoch 984/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1057 - val_loss: 0.5410\n",
      "Epoch 985/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1913 - val_loss: 1.0163\n",
      "Epoch 986/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3262 - val_loss: 0.5897\n",
      "Epoch 987/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.5546\n",
      "Epoch 988/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.5187\n",
      "Epoch 989/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.4681\n",
      "Epoch 990/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.7840\n",
      "Epoch 991/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.4671\n",
      "Epoch 992/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.4614\n",
      "Epoch 993/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.5722\n",
      "Epoch 994/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.4855\n",
      "Epoch 995/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.5390\n",
      "Epoch 996/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.5066\n",
      "Epoch 997/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.5241\n",
      "Epoch 998/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.4753\n",
      "Epoch 999/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.6007\n",
      "Epoch 1000/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1058 - val_loss: 0.6456\n",
      "Epoch 1001/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.4543\n",
      "Epoch 1002/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.5272\n",
      "Epoch 1003/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.4612\n",
      "Epoch 1004/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.5587\n",
      "Epoch 1005/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1265 - val_loss: 0.7898\n",
      "Epoch 1006/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1553 - val_loss: 0.5802\n",
      "Epoch 1007/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.4530\n",
      "Epoch 1008/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.5579\n",
      "Epoch 1009/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.5452\n",
      "Epoch 1010/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.4488\n",
      "Epoch 1011/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0569 - val_loss: 0.5313\n",
      "Epoch 1012/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1668 - val_loss: 0.4895\n",
      "Epoch 1013/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1126 - val_loss: 0.4608\n",
      "Epoch 1014/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.5493\n",
      "Epoch 1015/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0598 - val_loss: 0.6722\n",
      "Epoch 1016/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.5512\n",
      "Epoch 1017/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.5088\n",
      "Epoch 1018/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1165 - val_loss: 0.6144\n",
      "Epoch 1019/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1416 - val_loss: 0.7796\n",
      "Epoch 1020/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.7138\n",
      "Epoch 1021/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.6133\n",
      "Epoch 1022/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.5787\n",
      "Epoch 1023/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0424 - val_loss: 0.5389\n",
      "Epoch 1024/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.5877\n",
      "Epoch 1025/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.5172\n",
      "Epoch 1026/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.5018\n",
      "Epoch 1027/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.5350\n",
      "Epoch 1028/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.5327\n",
      "Epoch 1029/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.5213\n",
      "Epoch 1030/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.5998\n",
      "Epoch 1031/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.5449\n",
      "Epoch 1032/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.4974\n",
      "Epoch 1033/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.5450\n",
      "Epoch 1034/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.5527\n",
      "Epoch 1035/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0320 - val_loss: 0.5159\n",
      "Epoch 1036/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.5231\n",
      "Epoch 1037/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.5286\n",
      "Epoch 1038/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.6031\n",
      "Epoch 1039/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.5085\n",
      "Epoch 1040/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.5940\n",
      "Epoch 1041/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.5022\n",
      "Epoch 1042/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.6220\n",
      "Epoch 1043/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.5414\n",
      "Epoch 1044/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.5446\n",
      "Epoch 1045/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.5973\n",
      "Epoch 1046/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.4653\n",
      "Epoch 1047/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.5586\n",
      "Epoch 1048/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.4968\n",
      "Epoch 1049/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.6596\n",
      "Epoch 1050/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.4846\n",
      "Epoch 1051/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.5427\n",
      "Epoch 1052/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.5221\n",
      "Epoch 1053/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0314 - val_loss: 0.5585\n",
      "Epoch 1054/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.5254\n",
      "Epoch 1055/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.5071\n",
      "Epoch 1056/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.5801\n",
      "Epoch 1057/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.4998\n",
      "Epoch 1058/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.5889\n",
      "Epoch 1059/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.5619\n",
      "Epoch 1060/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.5508\n",
      "Epoch 1061/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.6632\n",
      "Epoch 1062/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0933 - val_loss: 0.5523\n",
      "Epoch 1063/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.5350\n",
      "Epoch 1064/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.5711\n",
      "Epoch 1065/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0414 - val_loss: 0.5464\n",
      "Epoch 1066/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.5456\n",
      "Epoch 1067/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.5326\n",
      "Epoch 1068/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.5229\n",
      "Epoch 1069/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.5708\n",
      "Epoch 1070/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.5139\n",
      "Epoch 1071/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0561 - val_loss: 0.5492\n",
      "Epoch 1072/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.5661\n",
      "Epoch 1073/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.5588\n",
      "Epoch 1074/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1542 - val_loss: 1.0078\n",
      "Epoch 1075/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2319 - val_loss: 0.6284\n",
      "Epoch 1076/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1131 - val_loss: 0.5066\n",
      "Epoch 1077/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0944 - val_loss: 0.5285\n",
      "Epoch 1078/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.5519\n",
      "Epoch 1079/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.5300\n",
      "Epoch 1080/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.6340\n",
      "Epoch 1081/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.6367\n",
      "Epoch 1082/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.6079\n",
      "Epoch 1083/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.5478\n",
      "Epoch 1084/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.6681\n",
      "Epoch 1085/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.5169\n",
      "Epoch 1086/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.5851\n",
      "Epoch 1087/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.5266\n",
      "Epoch 1088/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.5481\n",
      "Epoch 1089/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.5844\n",
      "Epoch 1090/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0427 - val_loss: 0.5858\n",
      "Epoch 1091/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.4855\n",
      "Epoch 1092/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.5912\n",
      "Epoch 1093/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1278 - val_loss: 0.8353\n",
      "Epoch 1094/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2020 - val_loss: 0.4874\n",
      "Epoch 1095/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.6320\n",
      "Epoch 1096/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.6339\n",
      "Epoch 1097/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.6107\n",
      "Epoch 1098/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.5490\n",
      "Epoch 1099/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.6219\n",
      "Epoch 1100/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.6147\n",
      "Epoch 1101/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.5810\n",
      "Epoch 1102/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.6066\n",
      "Epoch 1103/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.5578\n",
      "Epoch 1104/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.5490\n",
      "Epoch 1105/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.4933\n",
      "Epoch 1106/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.5408\n",
      "Epoch 1107/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.6075\n",
      "Epoch 1108/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.6085\n",
      "Epoch 1109/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.5617\n",
      "Epoch 1110/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.6220\n",
      "Epoch 1111/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.5802\n",
      "Epoch 1112/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0342 - val_loss: 0.5819\n",
      "Epoch 1113/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.5548\n",
      "Epoch 1114/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.5626\n",
      "Epoch 1115/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.5225\n",
      "Epoch 1116/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.6324\n",
      "Epoch 1117/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1018 - val_loss: 0.5257\n",
      "Epoch 1118/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0862 - val_loss: 0.5343\n",
      "Epoch 1119/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1114 - val_loss: 0.6302\n",
      "Epoch 1120/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0949 - val_loss: 0.6373\n",
      "Epoch 1121/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1362 - val_loss: 0.6125\n",
      "Epoch 1122/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.5541\n",
      "Epoch 1123/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.5952\n",
      "Epoch 1124/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.5732\n",
      "Epoch 1125/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.5748\n",
      "Epoch 1126/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.5938\n",
      "Epoch 1127/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.5829\n",
      "Epoch 1128/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.5635\n",
      "Epoch 1129/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.5470\n",
      "Epoch 1130/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.6055\n",
      "Epoch 1131/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.5877\n",
      "Epoch 1132/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.5888\n",
      "Epoch 1133/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.6648\n",
      "Epoch 1134/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.5345\n",
      "Epoch 1135/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.5486\n",
      "Epoch 1136/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0986 - val_loss: 0.5664\n",
      "Epoch 1137/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1276 - val_loss: 0.5052\n",
      "Epoch 1138/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1152 - val_loss: 0.6272\n",
      "Epoch 1139/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.6909\n",
      "Epoch 1140/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.7288\n",
      "Epoch 1141/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0320 - val_loss: 0.5878\n",
      "Epoch 1142/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.6579\n",
      "Epoch 1143/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.5462\n",
      "Epoch 1144/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.6289\n",
      "Epoch 1145/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0709 - val_loss: 0.5548\n",
      "Epoch 1146/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0419 - val_loss: 0.5477\n",
      "Epoch 1147/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.6610\n",
      "Epoch 1148/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.6219\n",
      "Epoch 1149/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.6062\n",
      "Epoch 1150/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.5842\n",
      "Epoch 1151/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.5805\n",
      "Epoch 1152/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.6989\n",
      "Epoch 1153/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.6776\n",
      "Epoch 1154/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.6435\n",
      "Epoch 1155/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.5918\n",
      "Epoch 1156/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.6837\n",
      "Epoch 1157/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.5851\n",
      "Epoch 1158/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.5426\n",
      "Epoch 1159/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.5474\n",
      "Epoch 1160/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.4963\n",
      "Epoch 1161/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.5653\n",
      "Epoch 1162/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.5423\n",
      "Epoch 1163/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.6026\n",
      "Epoch 1164/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.5214\n",
      "Epoch 1165/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.5355\n",
      "Epoch 1166/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.6185\n",
      "Epoch 1167/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.5214\n",
      "Epoch 1168/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.5780\n",
      "Epoch 1169/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.5121\n",
      "Epoch 1170/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.5360\n",
      "Epoch 1171/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1152 - val_loss: 0.6064\n",
      "Epoch 1172/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1637 - val_loss: 0.6415\n",
      "Epoch 1173/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1639 - val_loss: 0.4902\n",
      "Epoch 1174/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1101 - val_loss: 0.5724\n",
      "Epoch 1175/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.6949\n",
      "Epoch 1176/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0925 - val_loss: 0.4922\n",
      "Epoch 1177/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.5681\n",
      "Epoch 1178/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.7327\n",
      "Epoch 1179/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.5184\n",
      "Epoch 1180/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.6774\n",
      "Epoch 1181/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.5685\n",
      "Epoch 1182/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0336 - val_loss: 0.6124\n",
      "Epoch 1183/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.6380\n",
      "Epoch 1184/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.5773\n",
      "Epoch 1185/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.7111\n",
      "Epoch 1186/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.6401\n",
      "Epoch 1187/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.5274\n",
      "Epoch 1188/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.7059\n",
      "Epoch 1189/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.4977\n",
      "Epoch 1190/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 1.1251\n",
      "Epoch 1191/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.5832\n",
      "Epoch 1192/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.6528\n",
      "Epoch 1193/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.5531\n",
      "Epoch 1194/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.6013\n",
      "Epoch 1195/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.5863\n",
      "Epoch 1196/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.5929\n",
      "Epoch 1197/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.5925\n",
      "Epoch 1198/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.5272\n",
      "Epoch 1199/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.6446\n",
      "Epoch 1200/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.5562\n",
      "Epoch 1201/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.5821\n",
      "Epoch 1202/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.5627\n",
      "Epoch 1203/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.6414\n",
      "Epoch 1204/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.6632\n",
      "Epoch 1205/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.6589\n",
      "Epoch 1206/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1373 - val_loss: 0.6718\n",
      "Epoch 1207/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.6537\n",
      "Epoch 1208/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.6160\n",
      "Epoch 1209/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.5923\n",
      "Epoch 1210/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.6460\n",
      "Epoch 1211/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.5912\n",
      "Epoch 1212/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.6228\n",
      "Epoch 1213/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.6487\n",
      "Epoch 1214/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.7553\n",
      "Epoch 1215/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.5893\n",
      "Epoch 1216/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.6132\n",
      "Epoch 1217/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.7038\n",
      "Epoch 1218/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1353 - val_loss: 0.6892\n",
      "Epoch 1219/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.5138\n",
      "Epoch 1220/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.5857\n",
      "Epoch 1221/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.6062\n",
      "Epoch 1222/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.6513\n",
      "Epoch 1223/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.5245\n",
      "Epoch 1224/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.6716\n",
      "Epoch 1225/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.6317\n",
      "Epoch 1226/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.5692\n",
      "Epoch 1227/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.5678\n",
      "Epoch 1228/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.6218\n",
      "Epoch 1229/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1110 - val_loss: 0.6064\n",
      "Epoch 1230/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.6176\n",
      "Epoch 1231/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1010 - val_loss: 0.6258\n",
      "Epoch 1232/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.6266\n",
      "Epoch 1233/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.5594\n",
      "Epoch 1234/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.5366\n",
      "Epoch 1235/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.6161\n",
      "Epoch 1236/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.6987\n",
      "Epoch 1237/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.5720\n",
      "Epoch 1238/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.7220\n",
      "Epoch 1239/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.5544\n",
      "Epoch 1240/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.5589\n",
      "Epoch 1241/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.5922\n",
      "Epoch 1242/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0419 - val_loss: 0.5769\n",
      "Epoch 1243/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.6115\n",
      "Epoch 1244/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.6379\n",
      "Epoch 1245/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.5717\n",
      "Epoch 1246/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.5461\n",
      "Epoch 1247/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.5931\n",
      "Epoch 1248/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.5496\n",
      "Epoch 1249/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.6363\n",
      "Epoch 1250/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.5717\n",
      "Epoch 1251/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.5760\n",
      "Epoch 1252/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.5955\n",
      "Epoch 1253/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.5619\n",
      "Epoch 1254/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.6251\n",
      "Epoch 1255/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0560 - val_loss: 0.5663\n",
      "Epoch 1256/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.5782\n",
      "Epoch 1257/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.5888\n",
      "Epoch 1258/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.6343\n",
      "Epoch 1259/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.6904\n",
      "Epoch 1260/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.5923\n",
      "Epoch 1261/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.5084\n",
      "Epoch 1262/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.5675\n",
      "Epoch 1263/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.6027\n",
      "Epoch 1264/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.5479\n",
      "Epoch 1265/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.6113\n",
      "Epoch 1266/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.5548\n",
      "Epoch 1267/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.6021\n",
      "Epoch 1268/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.6093\n",
      "Epoch 1269/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.5454\n",
      "Epoch 1270/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.5382\n",
      "Epoch 1271/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.5841\n",
      "Epoch 1272/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.5473\n",
      "Epoch 1273/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.5699\n",
      "Epoch 1274/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.5837\n",
      "Epoch 1275/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.5592\n",
      "Epoch 1276/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.5751\n",
      "Epoch 1277/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.5858\n",
      "Epoch 1278/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.5010\n",
      "Epoch 1279/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.6418\n",
      "Epoch 1280/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.5402\n",
      "Epoch 1281/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.4883\n",
      "Epoch 1282/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.7229\n",
      "Epoch 1283/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.6126\n",
      "Epoch 1284/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.6572\n",
      "Epoch 1285/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.5867\n",
      "Epoch 1286/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.5351\n",
      "Epoch 1287/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 0.7485\n",
      "Epoch 1288/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1036 - val_loss: 0.5581\n",
      "Epoch 1289/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1575 - val_loss: 0.5912\n",
      "Epoch 1290/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.5385\n",
      "Epoch 1291/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.5093\n",
      "Epoch 1292/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.4972\n",
      "Epoch 1293/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 0.5327\n",
      "Epoch 1294/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.5592\n",
      "Epoch 1295/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.5126\n",
      "Epoch 1296/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.6804\n",
      "Epoch 1297/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.4742\n",
      "Epoch 1298/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.5945\n",
      "Epoch 1299/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.5798\n",
      "Epoch 1300/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.6840\n",
      "Epoch 1301/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.7341\n",
      "Epoch 1302/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0349 - val_loss: 0.4692\n",
      "Epoch 1303/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0324 - val_loss: 0.6358\n",
      "Epoch 1304/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.6853\n",
      "Epoch 1305/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.5347\n",
      "Epoch 1306/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.5932\n",
      "Epoch 1307/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.5825\n",
      "Epoch 1308/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.6538\n",
      "Epoch 1309/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.5448\n",
      "Epoch 1310/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.6563\n",
      "Epoch 1311/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.5647\n",
      "Epoch 1312/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0340 - val_loss: 0.5944\n",
      "Epoch 1313/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.6169\n",
      "Epoch 1314/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.5399\n",
      "Epoch 1315/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.5290\n",
      "Epoch 1316/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.5527\n",
      "Epoch 1317/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.5400\n",
      "Epoch 1318/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.5361\n",
      "Epoch 1319/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.6085\n",
      "Epoch 1320/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.5176\n",
      "Epoch 1321/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.5582\n",
      "Epoch 1322/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.6403\n",
      "Epoch 1323/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.4663\n",
      "Epoch 1324/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.6669\n",
      "Epoch 1325/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.6364\n",
      "Epoch 1326/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.6646\n",
      "Epoch 1327/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1152 - val_loss: 0.6356\n",
      "Epoch 1328/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0890 - val_loss: 0.5735\n",
      "Epoch 1329/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.5128\n",
      "Epoch 1330/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.5647\n",
      "Epoch 1331/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.5928\n",
      "Epoch 1332/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.5776\n",
      "Epoch 1333/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.6625\n",
      "Epoch 1334/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.5496\n",
      "Epoch 1335/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0304 - val_loss: 0.5335\n",
      "Epoch 1336/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.6383\n",
      "Epoch 1337/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.6254\n",
      "Epoch 1338/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1205 - val_loss: 0.5483\n",
      "Epoch 1339/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.6100\n",
      "Epoch 1340/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.9335\n",
      "Epoch 1341/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.5456\n",
      "Epoch 1342/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.5629\n",
      "Epoch 1343/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.6693\n",
      "Epoch 1344/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.5315\n",
      "Epoch 1345/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.6158\n",
      "Epoch 1346/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.6324\n",
      "Epoch 1347/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0505 - val_loss: 0.6306\n",
      "Epoch 1348/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.7374\n",
      "Epoch 1349/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.7183\n",
      "Epoch 1350/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0532 - val_loss: 0.7703\n",
      "Epoch 1351/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.5964\n",
      "Epoch 1352/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.6160\n",
      "Epoch 1353/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.7146\n",
      "Epoch 1354/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.7053\n",
      "Epoch 1355/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0419 - val_loss: 0.5967\n",
      "Epoch 1356/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.9109\n",
      "Epoch 1357/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2764 - val_loss: 0.7237\n",
      "Epoch 1358/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1724 - val_loss: 0.7203\n",
      "Epoch 1359/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.7014\n",
      "Epoch 1360/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.7514\n",
      "Epoch 1361/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.7817\n",
      "Epoch 1362/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1516 - val_loss: 1.3172\n",
      "Epoch 1363/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2483 - val_loss: 0.6587\n",
      "Epoch 1364/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.8052\n",
      "Epoch 1365/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.6663\n",
      "Epoch 1366/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.6820\n",
      "Epoch 1367/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 0.6307\n",
      "Epoch 1368/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.6186\n",
      "Epoch 1369/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1513 - val_loss: 0.6838\n",
      "Epoch 1370/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.7682\n",
      "Epoch 1371/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.7072\n",
      "Epoch 1372/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0322 - val_loss: 0.6013\n",
      "Epoch 1373/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.7901\n",
      "Epoch 1374/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.6827\n",
      "Epoch 1375/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.7088\n",
      "Epoch 1376/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.6613\n",
      "Epoch 1377/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.6199\n",
      "Epoch 1378/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.6509\n",
      "Epoch 1379/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.6972\n",
      "Epoch 1380/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.6577\n",
      "Epoch 1381/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.6639\n",
      "Epoch 1382/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.6268\n",
      "Epoch 1383/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.7598\n",
      "Epoch 1384/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.6697\n",
      "Epoch 1385/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.7384\n",
      "Epoch 1386/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.7033\n",
      "Epoch 1387/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.6387\n",
      "Epoch 1388/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.6708\n",
      "Epoch 1389/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0324 - val_loss: 0.6986\n",
      "Epoch 1390/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.6790\n",
      "Epoch 1391/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.6463\n",
      "Epoch 1392/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.6785\n",
      "Epoch 1393/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.6864\n",
      "Epoch 1394/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.7054\n",
      "Epoch 1395/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.6982\n",
      "Epoch 1396/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.5741\n",
      "Epoch 1397/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.6100\n",
      "Epoch 1398/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0339 - val_loss: 0.6629\n",
      "Epoch 1399/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.6570\n",
      "Epoch 1400/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.6753\n",
      "Epoch 1401/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.6265\n",
      "Epoch 1402/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.7259\n",
      "Epoch 1403/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.6307\n",
      "Epoch 1404/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.6881\n",
      "Epoch 1405/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.6670\n",
      "Epoch 1406/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.7214\n",
      "Epoch 1407/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.7289\n",
      "Epoch 1408/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.7123\n",
      "Epoch 1409/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.5998\n",
      "Epoch 1410/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0304 - val_loss: 0.7378\n",
      "Epoch 1411/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.7090\n",
      "Epoch 1412/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.7391\n",
      "Epoch 1413/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.6146\n",
      "Epoch 1414/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.6709\n",
      "Epoch 1415/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.6701\n",
      "Epoch 1416/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.5816\n",
      "Epoch 1417/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0329 - val_loss: 0.6479\n",
      "Epoch 1418/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.6143\n",
      "Epoch 1419/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.5735\n",
      "Epoch 1420/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.6346\n",
      "Epoch 1421/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.5834\n",
      "Epoch 1422/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.5902\n",
      "Epoch 1423/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.6695\n",
      "Epoch 1424/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.6517\n",
      "Epoch 1425/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.5534\n",
      "Epoch 1426/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.6868\n",
      "Epoch 1427/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.6448\n",
      "Epoch 1428/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.6405\n",
      "Epoch 1429/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.6968\n",
      "Epoch 1430/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0336 - val_loss: 0.6914\n",
      "Epoch 1431/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.7094\n",
      "Epoch 1432/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.6930\n",
      "Epoch 1433/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.5839\n",
      "Epoch 1434/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.7322\n",
      "Epoch 1435/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.6051\n",
      "Epoch 1436/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.6613\n",
      "Epoch 1437/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.6727\n",
      "Epoch 1438/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.6660\n",
      "Epoch 1439/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.6230\n",
      "Epoch 1440/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.6376\n",
      "Epoch 1441/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.6924\n",
      "Epoch 1442/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.6469\n",
      "Epoch 1443/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.6823\n",
      "Epoch 1444/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.6264\n",
      "Epoch 1445/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.7593\n",
      "Epoch 1446/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.6884\n",
      "Epoch 1447/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.6282\n",
      "Epoch 1448/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.6975\n",
      "Epoch 1449/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.5845\n",
      "Epoch 1450/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.7299\n",
      "Epoch 1451/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.6271\n",
      "Epoch 1452/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.6137\n",
      "Epoch 1453/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.7073\n",
      "Epoch 1454/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0339 - val_loss: 0.6640\n",
      "Epoch 1455/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.8128\n",
      "Epoch 1456/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.7968\n",
      "Epoch 1457/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1972 - val_loss: 1.1696\n",
      "Epoch 1458/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1003 - val_loss: 0.8971\n",
      "Epoch 1459/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.7110\n",
      "Epoch 1460/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.7707\n",
      "Epoch 1461/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.6359\n",
      "Epoch 1462/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.6630\n",
      "Epoch 1463/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0495 - val_loss: 0.6341\n",
      "Epoch 1464/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.7218\n",
      "Epoch 1465/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.5008\n",
      "Epoch 1466/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.7677\n",
      "Epoch 1467/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.6696\n",
      "Epoch 1468/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.6252\n",
      "Epoch 1469/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0340 - val_loss: 0.6266\n",
      "Epoch 1470/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.5650\n",
      "Epoch 1471/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.7661\n",
      "Epoch 1472/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.5660\n",
      "Epoch 1473/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.6747\n",
      "Epoch 1474/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.6410\n",
      "Epoch 1475/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.7503\n",
      "Epoch 1476/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0336 - val_loss: 0.7022\n",
      "Epoch 1477/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.8608\n",
      "Epoch 1478/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.9072\n",
      "Epoch 1479/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0822 - val_loss: 0.7275\n",
      "Epoch 1480/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0663 - val_loss: 0.7070\n",
      "Epoch 1481/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.9193\n",
      "Epoch 1482/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 0.5083\n",
      "Epoch 1483/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0849 - val_loss: 0.7418\n",
      "Epoch 1484/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.6123\n",
      "Epoch 1485/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.9010\n",
      "Epoch 1486/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.7729\n",
      "Epoch 1487/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.6834\n",
      "Epoch 1488/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.7115\n",
      "Epoch 1489/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.7287\n",
      "Epoch 1490/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.6568\n",
      "Epoch 1491/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.7495\n",
      "Epoch 1492/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.7153\n",
      "Epoch 1493/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.6618\n",
      "Epoch 1494/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.6624\n",
      "Epoch 1495/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.6745\n",
      "Epoch 1496/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.7583\n",
      "Epoch 1497/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.6554\n",
      "Epoch 1498/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.6938\n",
      "Epoch 1499/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.6670\n",
      "Epoch 1500/1500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.7079\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (10, 50)                  200       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (10, 50)                  2550      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (10, 50)                  2550      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (10, 50)                  2550      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (10, 50)                  2550      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (10, 1)                   51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=10,epochs=1500)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84cebfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23a429a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9793936329921601"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(tahmin,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55760da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.841390775044276"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(tahmin,y_test))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "347b989d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y_test[\"Sales\"],tahmin)\n",
    "plt.xlabel('Test Verileri')\n",
    "plt.ylabel('Tahmin Verileri')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "733ece43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[27.199072]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[276.9,48.9,41.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be2b2afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[103.62905]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[1000,200,160]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e77929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[33.508972]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[0,0,1000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7365cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[34.874043]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[0,1000,0]]) #The most successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57cd9707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[31.686522]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[1000,0,0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
